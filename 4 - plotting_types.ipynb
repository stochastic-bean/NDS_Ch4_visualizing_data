{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec6467a-2818-477b-8528-93239f2c44cb",
   "metadata": {},
   "source": [
    "# Thinking About Data for Plotting\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the difference between continuous and categorical data\n",
    "- Understand what nested data is\n",
    "- Understand why it is important to consider nesting structures when computing and visualizing variance\n",
    "- Understand the differences between wide- and long-format data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86df21-440b-41a9-9b34-d74dc7d21abc",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Visualization is an incredibly powerful way to present data. However, to generate effective plots, you need to understand the structure and organization of your data. In particular, you need to consider the different **variables** present in your data, whether they are **continuous** or **categorical**, and whether they are **nested** (often called *repeated measures*). In this lesson we'll review these different types of data and some common approaches to plotting them. \n",
    "\n",
    "Since we've worked with the Gapminder GDP data set a bit, let's look at it now and discuss the data types and structure. We'll read in the Oceania data set (which has only two countries) and then display the DataFrame:\n",
    "\n",
    "~~~python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/gapminder_gdp_oceania.csv', index_col='country')\n",
    "df\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ad90e-372c-47a6-811d-1e2032265a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d8efa6e-2f26-47d5-815d-7c6592d9b332",
   "metadata": {},
   "source": [
    "## Continuous Data\n",
    "\n",
    "Continuous data comprises most numeric data that you will encounter. Values can range continuously (i.e., in very small steps) across some range of values (possibly infinite, but typically with practical bounds when dealing with neuroscientific or psychological data). Continuous variables in psychology and neuroscience can include reaction times, voltage measurements in electrophysiology, fMRI activation levels, etc.. In Python, numeric data are typically stored as integers or floating point numbers. \n",
    "\n",
    "### Thought Question\n",
    "In the Gapminder GDP dataset shown above, what variables are continuous?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea3938-917d-46b1-b169-46b0e99bf171",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6e24e49-7918-4c9b-8185-8af33ef5b457",
   "metadata": {},
   "source": [
    "## Categorical Data\n",
    "\n",
    "Categorical data comprises most data that is not numeric. For example, in a drug study someone might receive an experimental drug or a placebo — it's one or the other. Or in a language study, each participant might be classified as a native English speaker or someone who learned English as a second language. Categorical data can include data that have some degree of continuity. For example, Some people learn English from their parents as the only language they hear in the first year of their lives, whereas others may hear another language at home but learn English fluently from an early age, from other kids in the neighborhood. So in many cases, we *treat* data as categorical — often for convenience — even when there are subtleties that are lost.\n",
    "\n",
    "### Thought Question\n",
    "What variable(s) in the Gapminder GDP set are categorical?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bfc60c-fe27-4d82-8c56-f6d49d899b06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c57a8e9-6623-4efc-9844-68fadb003a60",
   "metadata": {},
   "source": [
    "## Ordinal Data\n",
    "\n",
    "Another type of data that you may occasionally encounter is **ordinal data**. Ordinal data are *ordered* (hence the stem *ord-*), and as such fall somewhere between continuous and categorical data. Ordinal data can be distinguished from continuous data in that the levels (values) of an ordinal variable are *discrete* steps, which are ranked (i.e., ordered). Thus the steps between each level of an ordinal variable are treated as equivalent in magnitude. This is different from  continuous data, where the differences between values are quantifiable and measurable. \n",
    "\n",
    "For instance, imagine we take measurements of the weight of an animal at 4 time points: when the animal is aged 1 day, 5 days, 10 days, and 28 days. If we treat time as a continuous variable, then the gaps between measurements are 4, 5, and 18 (in days). However, if we treat time as an ordinal variable, then the gaps between each measurement are all treated as 1. \n",
    "\n",
    "Treating data as ordinal can be useful for some types of categorical data in particular. For example, if we have ratings on a Likert scale such as *Never – Almost Never – Sometimes – Almost Always – Always*, then it makes sense to treat these are ordered, rather than as 5 unordered categories.\n",
    "\n",
    "For the time being we will focus on continuous and categorical data, but it is worth noting that there are other ways of representing data as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19a7d8-1f24-4590-a416-d87e3bc2e605",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Making Continuous Data Categorical\n",
    "\n",
    "Continuous data can sometimes be made categorical as well. For example, height is a continuous variable, but for convenience in a research study we might want to classify people as \"short\", \"medium\", or \"tall\" rather than their precise height in centimetres. In research with children, participants are often categorized into groups such as grades 1-2, grades 3-4, grades 5-6, instead of treating grade (or age) as a continuous variable. This process of turning continuous data into categorical is called **discretizing** (making discrete). It can be useful if the data you collect aren't as continuous as the possible range of values (e.g., children's academic knowledge and abilities are typically more related to their grade level than their chronological age), or for ease of generalization. If continuous data are split into only two categories (e.g., tall vs. short), this is called **binarizing** the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8d939-d29f-4fa7-91b0-132e24788976",
   "metadata": {},
   "source": [
    "## Plotting Continuous and Categorical Data\n",
    "\n",
    "Recognizing which variables are continuous or categorical is important, because in many cases you need to plot them differently. Continuous data lend themselves to things like continuous lines (e.g., regression lines) and scatterplots. In contrast, plotting categorical data typically involves different plot \"objects\" for each category, such as different bars in a bar graph, or different lines in a line plot. Often continuous and categorical data are combined in one plot, as shown below for the Gapminder GDP data, where each line shows the relationship between two continuous variables (year and GDP), and the categorical data are represented by separate lines for each country:\n",
    "\n",
    "~~~python\n",
    "df.columns = df.columns.str.strip('gdpPercap_')\n",
    "df.T.plot()\n",
    "plt.show()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4c1882-62ed-4931-bc3c-4d59966d331c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b16bc67-98ac-4430-8e45-c6703e0ae84d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Distributions\n",
    "\n",
    "A critical property of any data set is the **distribution** of values, also commonly called its **variance**. Variance is actually where *all the information* is. If every data point were the same, the data couldn't tell us anything. Data are only interesting, or informative, if it contains *meaningful variability*. Data science is founded on different ways of assessing variability and giving it meaning. Often we talk about *systematic variability*, in other words variability that we can attribute to some measurable, systematic difference. For example, if children in grades 1-2 have smaller vocabularies than children in grades 3-4, we can say that vocabulary size varies systematically according to some property of each child — specifically what grade they are in.\n",
    "\n",
    "A critical fact in data is that variance is always present, but is typically in part systematic — related to something we measure — and in part random (often called \"noise\"). Visualization is a useful tool in exploring data in order to identify possible systematic patterns in data. Critically, we need to visualize how the *distribution* of values of some measurement vary with respect to some other variable. The fact that there is random variability in all data (at least, all neuroscience and psychology data) means that we can't just look at the average values of data points in, say, each of two groups of school children. Their averages may be numerically different, but the critical question is whether the typical variability in their values differs systematically between higher and lower grades. Plotting distributions of data is a useful way of comparing distributions. Commonly in neuroscience and psychology, we also use statistical tests to estimate our level of certainty that a difference is believable. We will come to statistical testing later, but for now we focus on making inferences based on visualization of the data. Well-designed visualizations can actually provide the same level of precision and confidence as statistical testing.\n",
    "\n",
    "In the next lesson, in learning about the Seaborn plotting package we'll discuss visualizing distributions and making inferences from them. Below is a preview – a box plot which shows the distribution of GDP values across all years, for each country. If you're not familiar with box plots, the Seaborn chapter will bring you up to speed.\n",
    "\n",
    "~~~python\n",
    "import seaborn as sns \n",
    "df = df.melt(var_name='year', value_name='GDP', ignore_index=False)\n",
    "sns.catplot(kind='box',\n",
    "           data=df.reset_index(), \n",
    "           x='country', y='GDP')\n",
    "\n",
    "plt.show()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b833dd6c-9346-44c0-8ac4-6655a9bafd13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3792ab50-08fb-4081-b0ca-1d7a19eeb052",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Nested Data\n",
    "\n",
    "Nested data occur when some measurements are \"nested\" or isolated inside other variables. This is very common in cognitive and neuroscience research, where we take many measurements from each individual participant (e.g., lots of experimental trials, recording from multiple electrodes). Indeed, nested data is often called **repeated measures** because repeated measurements are taken from the same \"unit\" of data (such as a human or animal participant). Nested data can be continuous or categorical, but the variable that they are nested inside is almost always categorical (e.g., individual people or animals). \n",
    "\n",
    "Examples of nested data include reaction times (RTs) obtained across a number of experimental trials from the same participant. Often data are **recursively nested**, meaning that there are multiple layers of nesting. For example, in a typical RT experiment, there are multiple experimental conditions, each with many trials, administered to each participant. In this case, RTs on individual trials are nested within experimental conditions, which are in turn nested within individual participants. If the study involves multiple groups (e.g., patients vs. controls), then participants are further nested within groups. As another example, in educational research data may be collected from children in different schools; in this case data may be nested within each child, and children are in turn nested inside schools. \n",
    "\n",
    "Recognizing nested data is important because, the amount of variability within an individual (or other nesting category) may be different than the variability between individuals (or other categories). As discussed above, in exploratory data analysis (EDA) — as well as in statistics — measures of variability are an important way that we make inferences about the data. \n",
    "\n",
    "For example, say we run a reaction time experiment with 100 trials, and 10 participants. We thus have 100 x 10 = 1000 data points. The variability is likely lower within an individual than between – one participant may be on average 150 ms faster than another, but each individual may only show a variation of +/- 25 ms in their personal average reaction times. In this case, if we compute the average RT over all 1000 trials, without considering nesting structure, our measure of the variance across the 1000 trials will be very low (around 25 ms), because each individual contributes so many (similar) trials. But if we first average across the 100 trials for each participant, then compute the variability between these averages, we will capture just the person-to-person difference (which would be more like 150 ms in this example). In this case the variance reflects the true person-to-person variation, which is typically what we are interested in when running experiments across groups of individuals. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b00a7-94e9-4e4e-a260-f415554aca09",
   "metadata": {},
   "source": [
    "## Representations of Data\n",
    "\n",
    "After thinking about the structure (organization of data) at a conceptual level, we need to think about how this is actually stored in data files. Although this is an extensive subject, for now we will focus on data stored in pandas DataFrames, because pandas is a powerful tool and we've already started learning how to work with pandas. \n",
    "\n",
    "pandas DataFrames are a **two-dimensional** way of storing data. The two dimensions are rows and columns. But within this framework, we can store extremely complex data containing many values, and many variables as well. \n",
    "\n",
    "### Long- vs. Wide-Form Data\n",
    "\n",
    "Many software tools represent data in two-dimensional row-column format, including Microsoft Excel, Google Sheets, and SPSS. Across all of them, data can be stored in two ways.\n",
    "\n",
    "In **wide-form** data, each unit of obesrvation (such as a human or animal research participant) is associated with one measurement of each experimental variable. So each row in the DataFrame contains all the data from one participant, and columns represent individual measured variables, including different levels of the same variable. The Gapminder GDP data set is an example of wide-form data. Each row contains all the data associated with a particular country, and the columns represent all the different measurements we have. The data values in all of the columns are GDP in millions of dollars, and the different columns store data from different levels of the \"years\" variable.\n",
    "\n",
    "~~~python\n",
    "df = pd.read_csv('data/gapminder_gdp_europe.csv', index_col='country')\n",
    "df.head()\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee07a16-b38e-4524-a3e1-37b2897075dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e47964e3-d10b-486d-a5f5-e6cd249a936c",
   "metadata": {},
   "source": [
    "In contrast, **long-form** data requires fewer columns to represent a particular data set, but more rows. Measurements from a single source (e.g., experimental participant) are stored across several rows. Rather than each level of each variable having its own column, only two columns are required: one specifying the level of the variable, and one specifying the value of the measurement at that level of the variable, for that participant. If we were to convert the Gapminder GDP data to long form, rather than having many columns for the different years, we would have one column labeled \"year\", that contained different values of year (e.g., 1900, 1920, etc.) and a second column called \"GDP\" that contained the GDP values in millions of dollars. Thus each country would have as many rows in the DataFrame as there were years for which we had measurements. Long-form data is often used with nested (repeated measures) data. \n",
    "\n",
    "With pandas it's quite easy to convert wide-form data to long-form using the `.melt()` method. By default, `.melt()` will \"melt\" all of the data columns into one long column, and put the original column headings in a second column. We can use the kwargs `var_name=` and `value_name=` to name the columns that take the original column names and values in the columns, respectively.\n",
    "\n",
    "Below we convert the GDP data to long form as described above. Prior to doing so, we use another pandas method, `str.strip()`, to remove the leading text (`gdpPercap_`) from each column so that the resulting `year` column contains only the numerical year.\n",
    "\n",
    "~~~python\n",
    "df.columns = df.columns.str.strip('gdpPercap_')\n",
    "df = df.melt(var_name='year', value_name='GDP', ignore_index=False)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35cb692-fd02-44fb-b897-186a37086ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8954ae14-e34d-4f40-aae0-c29a6acf3e61",
   "metadata": {},
   "source": [
    "You can see below that after the row for the last country in 1952, the list of countries repeats again, now for the year 1957, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f4a50-c317-4f57-9846-2aa5baf72272",
   "metadata": {},
   "source": [
    "~~~python\n",
    "df.head(35)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156457a-08cb-47a7-bf4e-7904369e70aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e0addd5-a804-4925-8d80-064fd6bfc2c3",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "- Data are measurements, comprising a set of values\n",
    "- Each type of measurement can be called a **variable**\n",
    "- **Continuous variables** are typically numeric, and represent values sampled from a continuum — a continuous range\n",
    "- **Categorical variables** are those where values are one of a limited number of different categories\n",
    "- **Ordinal values** are ordered (ranked), but the steps between the levels of the variable are treated as equivalent\n",
    "- Continuous data can be made categorical by **discretizing** them. Similar values along the continuum are grouped into bins or categories for the purposes of simplification. If only two categories are created, this is called **binarizing** the data\n",
    "- It is important to understand the differences between continuous, categorical, and ordinal data because the nature of the data affects how you visualize, analyze, and interpret the data\n",
    "- Continuous data have a **distribution** of values, ranging from the minimum to maximum measured values. Distributions have other properties, including the median and inter-quartile range.\n",
    "- **Nested** data occur when one set of measurements is taken within another. For example, measurements of reaction time across trials may be nested within individual participants, or students may be nested within schools.\n",
    "- It is important to consider the nesting structure of data when examining variance, because variance is often lower within a nesting structure (e.g., across trials within a participant) than at the next-higher level (e.g., between participants). Conflating variance across nesting levels can artificially decrease the measurement of variance that is appropriate for inference (e.g., variance between individuals, not within, is typically most relevant in psychology and neuroscience studies).\n",
    "- Data can be represented in a 2D structure such as a spreadsheet or pandas DataFrame, as wide- or long-format\n",
    "- **Wide-format** data has levels of at least one categorical variable represented as separate columns (i.e., each level of the variable is a separate column)\n",
    "- **Long-format** data has one column for each variable, and one row for each measurement. Long-format data is generally preferred, and it is what we will primarily work with moving forward in this course.\n",
    "- Wide-format data can easily be converted to long-format data in pandas, using the `.melt()` method\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
